{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2016320101_박성범_FinalProject",
      "provenance": [],
      "authorship_tag": "ABX9TyO4Qpb4E+v/DBm/mhNvNVur"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxLb8o0n2TuO"
      },
      "source": [
        "# ML Final Project - Wine Quality Classifier\r\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqXbGOpV-xrG"
      },
      "source": [
        "## 0. Summary\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pydSPEXdbgPT"
      },
      "source": [
        "### Dataset\r\n",
        "- 12개의 Features, 6497개의 Instances를 갖는 Wine quality data 활용\r\n",
        "\r\n",
        "### Preprocessing\r\n",
        "- 결측값 처리(Missing value treatment): 결측값 제거\r\n",
        "- 이상치 처리(Outlier value treatment): IQR 방식 활용하여 제거\r\n",
        "- Scaler: Standard Scaler와 MinMax Scaler를 활용\r\n",
        "\r\n",
        "### Data Analyasis\r\n",
        "- 단변량 분석(Univariate Analysis): 히스토그램을 활용해 단변량 분석 진행\r\n",
        "- 다변량 분석(Multivariate Analysis): 상관관계 분석을 통해 'Alcohol' feature가 quality와 가장 큰 상관관계가 있음을 확인\r\n",
        "\r\n",
        "### Modeling & Experiment\r\n",
        "- ZeroR, Logistic Regression, KNN, Decision Tree 등 총 10개의 Model 실험\r\n",
        "- Train / Test Size를 0.8 : 0.2로 진행했으며, 5-fold Cross Validation을 수행\r\n",
        "- ZeroR의 Baseline은 43.8%로 관측\r\n",
        "- Convergence Warning을 없애기 위해 max_iter 값들을 조절했으며, 이외의 parameter들도 반복문을 통해 성능 평가\r\n",
        "- **최고 성능은 n_estimators를 tuining한 Random Forest에서 66.8%의 성능을 보임**\r\n",
        "\r\n",
        "### Feature Selection\r\n",
        "- 최고의 성능을 보인 Random Forest에서 feature importance를 확인한 결과, **correlation analysis에서<br> 가장 높은 상관관계를 보인 'alcohol' feature가 마찬가지로 가장 중요도가 높음**\r\n",
        "- Select K-best Feature Selection을 적용하였을 때 **small-size dataset이라는 한계 때문에 오히려 성능이 떨어지는 경향**을 보임\r\n",
        "\r\n",
        "### Clustering\r\n",
        "- 중간 정도의 quality인 5, 6, 7에서만 어느 정도 일치하는 경향을 보이며, 그 외에는 완전히 상반된 결과 도출\r\n",
        "- 이는 **quality 점수 자체가 중간에 몰려 있을 수 밖에 없는, wine quality dataset의 imbalanced class 한계**에서 비롯된 것으로 보임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ejbgGyD-57B"
      },
      "source": [
        "## 1. Dataset\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z02rgTWRMOfh"
      },
      "source": [
        "### Data 출처\r\n",
        "- Wine Quality Data: <https://www.kaggle.com/rajyellow46/wine-quality>  \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxLObiIEPxRD"
      },
      "source": [
        "### Data 설명\r\n",
        "- **12**개의 Features, **6497**개의 Instances 존재\r\n",
        "- 포르투갈에서 생산되는 비뉴 베르데(*Vinho Verde*) Red, White 와인에 관한 데이터셋\r\n",
        "- Privacy와 Logistic Issue로 인해, 물리 화학적(*physicochemical, inputs*)이고 감각적인(*sensory, the output*) Variable들만 존재 <br>(*포도의 종류, 와인 브랜드, 가격 등 제외* )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNWYVVeDPzKs"
      },
      "source": [
        "### Features\r\n",
        "Feature | 설명 | Type | 구분 |\r\n",
        ":---: | :---: | :---: | :---: |\r\n",
        "**Fixed Acidity(고정 산도)** | 주로 타르타르산(*tartaric*), 사과산(*malic*)으로 이루어져 있고, 와인의 산도를 제어 | Object | Input |\r\n",
        "**Volatile Acidity(휘발 산도)** | 와인의 향에 관여 | Float64 | Input |\r\n",
        "**Critic Acid(시트르산)** | 와인의 신선함을 올려주며, 산성화에 연관 | Float64  | Input |\r\n",
        "**Residual Sugar(잔여 설탕)** | 와인의 단맛에 관여 | Float64 | Input |\r\n",
        "**Chlorides(염화물)** | 짠맛의 원인이며, 와인의 신맛을 좌우 | Float64 | Input |\r\n",
        "**Free Sulfur Dioxide(자유 이산화황)** | 황 화합물은 박테리아와 효모를 억제해 와인 보존에 관여 | Float64 | Input |\r\n",
        "**Total Sulfur Dioxide(총 이산화황)** | 황 화합물은 박테리아와 효모를 억제해 와인 보존에 관여 | Float64 | Input |\r\n",
        "**Density(밀도)** | 와인 바디(*body*)의 높고 낮음을 표현하며, 와인의 무게감을 의미 | Float64 | Input |\r\n",
        "**pH(산성도)** | 와인의 신맛의 정도를 표현 | Float64 | Input |\r\n",
        "**Sulphates(황산염)** | 황 화합물은 박테리아와 효모를 억제해 와인 보존에 관여 | Float64 | Input |\r\n",
        "**Alchol(도수)** | 와인 발효 과정의 최종 부산물로, 물과 비교했을 때 끈적거리는 점성이 많아 <br>농도가 높을수록 입 안에서 무겁게, 적을수록 가볍게 느껴지는 등 와인의 바디(*body*)를 이루는데 기여 | Float64  | Input |\r\n",
        "**Quality(와인 품질)** | 최소 0점부터 최대 10점까지의 와인 품질 점수 | int64 | Label|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6qbnaLAj6B"
      },
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va23Rxn19BbV",
        "outputId": "45d730f8-b82b-40db-fcf2-cf1ca8bddb6c"
      },
      "source": [
        "# [Import Data]\r\n",
        "#   pandas library를 활용해 CSV파일 Import 및 Dataframe으로 변환\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "raw_df = pd.read_csv(\"https://raw.githubusercontent.com/Chu7zpah/Wine-quality-classifier/master/Wine_quality_dataset.csv\")\r\n",
        "print(\"[First 5 Rows]\")\r\n",
        "print(raw_df.head())\r\n",
        "print(\"\\n\\n[Last 5 Rows]\")\r\n",
        "print(raw_df.tail())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[First 5 Rows]\n",
            "    type  fixed acidity  volatile acidity  ...  sulphates  alcohol  quality\n",
            "0  white            7.0              0.27  ...       0.45      8.8        6\n",
            "1  white            6.3              0.30  ...       0.49      9.5        6\n",
            "2  white            8.1              0.28  ...       0.44     10.1        6\n",
            "3  white            7.2              0.23  ...       0.40      9.9        6\n",
            "4  white            7.2              0.23  ...       0.40      9.9        6\n",
            "\n",
            "[5 rows x 13 columns]\n",
            "\n",
            "\n",
            "[Last 5 Rows]\n",
            "     type  fixed acidity  volatile acidity  ...  sulphates  alcohol  quality\n",
            "6492  red            6.2             0.600  ...       0.58     10.5        5\n",
            "6493  red            5.9             0.550  ...        NaN     11.2        6\n",
            "6494  red            6.3             0.510  ...       0.75     11.0        6\n",
            "6495  red            5.9             0.645  ...       0.71     10.2        5\n",
            "6496  red            6.0             0.310  ...       0.66     11.0        6\n",
            "\n",
            "[5 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "hZs2rea0TD-D",
        "outputId": "3d7c5f43-e242-4213-c0c2-0e3b56f9c450"
      },
      "source": [
        "# Describe를 통한 Data 확인\r\n",
        "\r\n",
        "raw_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6487.000000</td>\n",
              "      <td>6489.000000</td>\n",
              "      <td>6494.000000</td>\n",
              "      <td>6495.000000</td>\n",
              "      <td>6495.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6488.000000</td>\n",
              "      <td>6493.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.216579</td>\n",
              "      <td>0.339691</td>\n",
              "      <td>0.318722</td>\n",
              "      <td>5.444326</td>\n",
              "      <td>0.056042</td>\n",
              "      <td>30.525319</td>\n",
              "      <td>115.744574</td>\n",
              "      <td>0.994697</td>\n",
              "      <td>3.218395</td>\n",
              "      <td>0.531215</td>\n",
              "      <td>10.491801</td>\n",
              "      <td>5.818378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.296750</td>\n",
              "      <td>0.164649</td>\n",
              "      <td>0.145265</td>\n",
              "      <td>4.758125</td>\n",
              "      <td>0.035036</td>\n",
              "      <td>17.749400</td>\n",
              "      <td>56.521855</td>\n",
              "      <td>0.002999</td>\n",
              "      <td>0.160748</td>\n",
              "      <td>0.148814</td>\n",
              "      <td>1.192712</td>\n",
              "      <td>0.873255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.009000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.987110</td>\n",
              "      <td>2.720000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.992340</td>\n",
              "      <td>3.110000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.994890</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.996990</td>\n",
              "      <td>3.320000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>11.300000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.900000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>65.800000</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>1.038980</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.900000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fixed acidity  volatile acidity  ...      alcohol      quality\n",
              "count    6487.000000       6489.000000  ...  6497.000000  6497.000000\n",
              "mean        7.216579          0.339691  ...    10.491801     5.818378\n",
              "std         1.296750          0.164649  ...     1.192712     0.873255\n",
              "min         3.800000          0.080000  ...     8.000000     3.000000\n",
              "25%         6.400000          0.230000  ...     9.500000     5.000000\n",
              "50%         7.000000          0.290000  ...    10.300000     6.000000\n",
              "75%         7.700000          0.400000  ...    11.300000     6.000000\n",
              "max        15.900000          1.580000  ...    14.900000     9.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPUf2-ahRMfo"
      },
      "source": [
        "##2. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1gE05hSRjNm"
      },
      "source": [
        "### 결측값 처리(Missing value treatment)\r\n",
        "- 분석에 영향을 주는 NA 값 확인 및 dropna() 메소드를 활용해 분석 범위에서 제외\r\n",
        "- 평균값이나 최빈값 등으로 대체하는 방안도 생각해 볼 수 있으나, 결측값이 많지 않아 성능을 높이기 위해 단순히 제거하는 방법을 선택\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abksrUc7SXgn",
        "outputId": "27b5cc55-2893-4c6d-f940-1f247a0377e6"
      },
      "source": [
        "# Column별 결측값 개수 확인\r\n",
        "\r\n",
        "raw_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type                     0\n",
              "fixed acidity           10\n",
              "volatile acidity         8\n",
              "citric acid              3\n",
              "residual sugar           2\n",
              "chlorides                2\n",
              "free sulfur dioxide      0\n",
              "total sulfur dioxide     0\n",
              "density                  0\n",
              "pH                       9\n",
              "sulphates                4\n",
              "alcohol                  0\n",
              "quality                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "8w__i6SdSXb3",
        "outputId": "521af6f9-cf21-4ffb-da63-dc74ffb3ae94"
      },
      "source": [
        "# 결측값 제외한 Data Frame 생성\r\n",
        "#   기존 6497개의 Instance에서, 결측값들을 제외해 Count가 모두 6463개로 통일됨을 확인 가능\r\n",
        "\r\n",
        "na_processed_df = raw_df.copy()\r\n",
        "na_processed_df.dropna(inplace=True)\r\n",
        "na_processed_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "      <td>6463.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.217755</td>\n",
              "      <td>0.339589</td>\n",
              "      <td>0.318758</td>\n",
              "      <td>5.443958</td>\n",
              "      <td>0.056056</td>\n",
              "      <td>30.516865</td>\n",
              "      <td>115.694492</td>\n",
              "      <td>0.994698</td>\n",
              "      <td>3.218332</td>\n",
              "      <td>0.531150</td>\n",
              "      <td>10.492825</td>\n",
              "      <td>5.818505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.297913</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>0.145252</td>\n",
              "      <td>4.756852</td>\n",
              "      <td>0.035076</td>\n",
              "      <td>17.758815</td>\n",
              "      <td>56.526736</td>\n",
              "      <td>0.003001</td>\n",
              "      <td>0.160650</td>\n",
              "      <td>0.148913</td>\n",
              "      <td>1.193128</td>\n",
              "      <td>0.873286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.009000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.987110</td>\n",
              "      <td>2.720000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.992330</td>\n",
              "      <td>3.110000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.994890</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.997000</td>\n",
              "      <td>3.320000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>11.300000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.900000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>65.800000</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>1.038980</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.900000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fixed acidity  volatile acidity  ...      alcohol      quality\n",
              "count    6463.000000       6463.000000  ...  6463.000000  6463.000000\n",
              "mean        7.217755          0.339589  ...    10.492825     5.818505\n",
              "std         1.297913          0.164639  ...     1.193128     0.873286\n",
              "min         3.800000          0.080000  ...     8.000000     3.000000\n",
              "25%         6.400000          0.230000  ...     9.500000     5.000000\n",
              "50%         7.000000          0.290000  ...    10.300000     6.000000\n",
              "75%         7.700000          0.400000  ...    11.300000     6.000000\n",
              "max        15.900000          1.580000  ...    14.900000     9.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymIwmw8GTWqy",
        "outputId": "eca118dc-6de5-4e96-84a8-f95a089f8a26"
      },
      "source": [
        "# 결측값이 제대로 제거되었는지 확인\r\n",
        "\r\n",
        "na_processed_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type                    0\n",
              "fixed acidity           0\n",
              "volatile acidity        0\n",
              "citric acid             0\n",
              "residual sugar          0\n",
              "chlorides               0\n",
              "free sulfur dioxide     0\n",
              "total sulfur dioxide    0\n",
              "density                 0\n",
              "pH                      0\n",
              "sulphates               0\n",
              "alcohol                 0\n",
              "quality                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSQcXwZo0gYr"
      },
      "source": [
        "### 이상치 처리(Outlier value treatment)\r\n",
        "- 분석에 영향을 주는 Outlier 값들을 처리\r\n",
        "- 여러가지 방식 중 IQR(InterQuartile Range) 방식을 활용하여 이상치 제거\r\n",
        "- 모든 Feature들의 Outlier를 제거하기보다는, std가 높은 '*free sulfur dioxide*' feature와 '*total sulfur dioxide*' feature에 대해서 이상치 처리\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Z03pyA5UyB"
      },
      "source": [
        "# IQR을 활용한 이상치 Index 반환 함수\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def get_outlier(df=None, column=None):\r\n",
        "  q1 = np.percentile(df[column].values, 25)\r\n",
        "  q3 = np.percentile(df[column].values, 75)\r\n",
        "  IQR = q3 - q1\r\n",
        "  lower_bound = q1 - (IQR * 1.5)\r\n",
        "  upper_bound = q3 + (IQR * 1.5)\r\n",
        "  \r\n",
        "  outlier_index = df[(df[column] < lower_bound) | (df[column] > upper_bound)].index\r\n",
        "  return outlier_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rLACeaz_EpO",
        "outputId": "e18ffcd3-bb9b-4379-afa3-f3dcec37fc18"
      },
      "source": [
        "cleaned_df = na_processed_df.copy()\r\n",
        "\r\n",
        "outlier_idx = get_outlier(cleaned_df, 'free sulfur dioxide')\r\n",
        "cleaned_df.drop(outlier_idx, axis=0, inplace=True)\r\n",
        "\r\n",
        "outlier_idx = get_outlier(cleaned_df, 'total sulfur dioxide')\r\n",
        "cleaned_df.drop(outlier_idx, axis=0, inplace=True)\r\n",
        "\r\n",
        "print(cleaned_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       type  fixed acidity  volatile acidity  ...  sulphates  alcohol  quality\n",
            "0     white            7.0             0.270  ...       0.45      8.8        6\n",
            "1     white            6.3             0.300  ...       0.49      9.5        6\n",
            "2     white            8.1             0.280  ...       0.44     10.1        6\n",
            "3     white            7.2             0.230  ...       0.40      9.9        6\n",
            "4     white            7.2             0.230  ...       0.40      9.9        6\n",
            "...     ...            ...               ...  ...        ...      ...      ...\n",
            "6491    red            6.8             0.620  ...       0.82      9.5        6\n",
            "6492    red            6.2             0.600  ...       0.58     10.5        5\n",
            "6494    red            6.3             0.510  ...       0.75     11.0        6\n",
            "6495    red            5.9             0.645  ...       0.71     10.2        5\n",
            "6496    red            6.0             0.310  ...       0.66     11.0        6\n",
            "\n",
            "[6394 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XljEA30XD4qM"
      },
      "source": [
        "### Data 및 Label 분리\r\n",
        "- Label인 *quality* feature 분리\r\n",
        "- Input feature들 중 Categorical feature인 *type* feature는 분석범위에서 제외<br> (Red, White의 종류는 Wine Quality와 상관관계가 존재하지 않는 Feature임이 자명하기 때문)\r\n",
        "- *type* feature를 제외한 나머지 feature들을 numeric_data로 분리\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA-f44bJD06T"
      },
      "source": [
        "# label 및 features 분리\r\n",
        "\r\n",
        "label = cleaned_df['quality']\r\n",
        "raw_data = cleaned_df.drop(columns=['quality'])\r\n",
        "numeric_data = raw_data.drop(columns=['type'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGZO9-GER2bB"
      },
      "source": [
        "## 3. Problem Statement\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwgO_FcaScbB"
      },
      "source": [
        "1. feature들의 분포는 어떠한가? - *univariate analysis* \r\n",
        "1. 어떤 feature가 Class인 *quality*와 가장 상관성이 높은가? - *correlation analysis*\r\n",
        "2. 어떤 Model이 주어진 feature들을 통한 quality classification을 가장 잘 설명할 수 있는가? - *model selection problem*\r\n",
        "3. 다양한 hyperparameter들을 조정하여 얻을 수 있는 best performance는 얼마인가? - *hyperparameter tuning*\r\n",
        "4. best performance를 얻은 model에서, 가장 중요한 3개의 feature는 무엇인가? - *feature selection problem*\r\n",
        "5. feature selection을 적용한 data에 대해 다시 model을 적용하였을 때 성능 차이는 어떠한가? - *feature selection problem*\r\n",
        "6. Clustering을 적용하였을 때에도 Classification Model과 유사한 결과를 얻을 수 있는가? - *unsupervised learning*\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sB-meJ7GsT2"
      },
      "source": [
        "## 4. Data Analysis\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkM9VwRH5STW"
      },
      "source": [
        "### Univariate Analysis (단변량분석)\r\n",
        "*히스토그램을 활용해 단변량분석 진행*\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AhTOafmG8dV"
      },
      "source": [
        "#### Histogram\r\n",
        "- 축의 Scale들을 종합해 보았을 때, *Alcohol* Feature가 가장 고르게 분포\r\n",
        "- Quality와의 높은 Correlation 또한 예상됨\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND3kpv_uBJpY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "148e2fcb-5075-4dd9-8d2a-0a1f090229ec"
      },
      "source": [
        "# 히스토그램을 활용한 단변수분석\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "rows = 3\r\n",
        "cols = 4\r\n",
        "fig, ax = plt.subplots(rows, cols)\r\n",
        "idx = 0\r\n",
        "\r\n",
        "for row in range(rows):\r\n",
        "  for col in range(cols):\r\n",
        "    if idx == 11:\r\n",
        "      break\r\n",
        "    ax[row, col].hist(numeric_data[f'{numeric_data.columns[idx]}'])\r\n",
        "    ax[row, col].set_title(f'{numeric_data.columns[idx]}')\r\n",
        "    ax[row, col].set_xlabel('value')\r\n",
        "    idx += 1\r\n",
        "\r\n",
        "fig.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqVRBkPuIoSS"
      },
      "source": [
        "### Multivariate Analysis (다변량분석)\r\n",
        "*Heatmap을 통해 Correlation Analyasis(상관변수 분석) 진행*\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_UJz0LtPlbG"
      },
      "source": [
        "\r\n",
        "#### Correlation Analysis\r\n",
        "- 단변량 분석에서 예상한 것처럼, **_Alcohol_** Feature가 0.6 정도의 Correlation으로 Label인 Quality와 가장 높은 상관관계를 보임\r\n",
        "- 앞서 Feature들에 대해 설명했을 때, 와인의 바디(body)를 결정하는데 관여했던 두 요소인 <br>*Alcohol*과 *Density* Feature가 0.8 정도의 높은 상관관계를 보임\r\n",
        "- Sulfur dioxide(이산화황)와 관련된 두 개의 Feature인 *Free sulfur dioxide*와 *Total sulfur dioxide* 또한 0.9 정도의 높은 상관관계를 보임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu3bgs4O_SiD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "33f48628-2ed2-4ff9-9103-308eacb2cbcd"
      },
      "source": [
        "import seaborn as sb\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "corr = np.abs(cleaned_df.corr())\r\n",
        "sb.heatmap(corr, square=True, cmap=\"PuBu\")\r\n",
        "plt.title(\"Correlation Analysis with absolute values\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G00HPok4Vvyw"
      },
      "source": [
        "### Problem Statements\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZMa45prb2-3"
      },
      "source": [
        "1. ~feature들의 분포는 어떠한가? - *univariate analysis*~\r\n",
        "1. ~어떤 feature가 Class인 *quality*와 가장 상관성이 높은가? - *correlation analysis*~\r\n",
        "2. 어떤 Model이 주어진 feature들을 통한 quality classification을 가장 잘 설명할 수 있는가? - *model selection problem*\r\n",
        "3. 다양한 hyperparameter들을 조정하여 얻을 수 있는 best performance는 얼마인가? - *hyperparameter tuning*\r\n",
        "4. best performance를 얻은 model에서, 가장 중요한 3개의 feature는 무엇인가? - *feature selection problem*\r\n",
        "5. feature selection을 적용한 data에 대해 다시 model을 적용하였을 때 성능 차이는 어떠한가? - *feature selection problem*\r\n",
        "6. Clustering을 적용하였을 때에도 Classification Model과 유사한 결과를 얻을 수 있는가? - *unsupervised learning*\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVpKtkuub4ZP"
      },
      "source": [
        "##5. Mode & Metrics\r\n",
        "*Multi-class classification Models, Experiment Metrics*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orCtaC6dcBbz"
      },
      "source": [
        "### Model 목록 및 선정 이유"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6WuVsW2cI_l"
      },
      "source": [
        "Model | Type | 선정 이유\r\n",
        ":---: | :---: | :---:\r\n",
        "**ZeroR** | Label-base Classifier | 가장 간단한 분류 방법으로, Label에만 의존<br><br>예측 능력은 없지만, **표준 성능을 가늠**하기 위해 사용\r\n",
        "**Gaussian Naive Bayes** | Probabilistic Classifier | Naive Bayes 확률에 기반한 Classifier<br><br>확률적 모델로도 해당 Wine quality를 잘 분류해 낼 수 있을지 확인하고자 실험\r\n",
        "**Logistic Regression** | Linear Model | Multiclass classification을 위해, logistic regression classifier를 사용<br><br>*'multiclass= '* parameter를 'ovr'과 'multinomial'로 구분지어 2개의 model 실험\r\n",
        "**Perceptron** | Linear Model | 간단한 Linear Model 중 하나인 Perceptron으로 실험<br><br>Multiclass classification인 만큼 좋은 성능을 기대하기는 어렵다고 예상\r\n",
        "**Decision Tree** | Tree | 널리 사용되는 classifier인 decision tree를 활용해 실험<br><br>Decision Tree의 특성상 Hyperparameter등을 적당히 조절할 경우 좋은 성능을 기대할 수 있으나,<br> **Overfitting**의 문제가 발생하기 쉬우므로 적절한 수준의 Overfitting handling이 필요할 것으로 예상됨\r\n",
        "**KNN(K-Nearest Neighbor)** | Instance Based Learning | Instance Based Learning 중 수업시간에 다룬 KNN 기법을 활용<br><br>최적의 성능을 보이는 *k*값은 얼마인지 실험\r\n",
        "**MLP(Multi-Layer Perceptron)** |Non-linear Model| 해당 Data가 어떠한 특징을 가지고 있는지 알 수 없기 때문에, <br>nonlinear한 Problem들을 다루기 위한 MLP 또한 실험<br><br>Iteration의 경우 Convergence Warning이 발생하지 않는 선에서 조절\r\n",
        "**Random Forest** | Ensemble | Ensemble 기법 중 하나인 Random Forest를 활용하여 Decision Tree의 **Overfitting 문제**를 완화하고,<br>Hyperparameter tuning을 통한 성능 개선을 실험\r\n",
        "**K-Means++** | Clustering | Unsupervised Learning 중 하나인 K-Means++ 알고리즘을 통해 Data 분류 및 supervised learning 알고리즘들과의 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZNWCN7poB0M"
      },
      "source": [
        "### Metrics\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwDNKBMzpRMt"
      },
      "source": [
        "#### Train/Test data size\r\n",
        "  - 이상치를 제거한 cleaned_df의 Instance 개수: 6394\r\n",
        "  - 비교적 small dataset에 속하기 때문에, Train(0.8) : Test(0.2)의 비율로 구성\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99WieJBnu76h"
      },
      "source": [
        "# Train/Test Data 분리\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(numeric_data, label, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3XwE2PCu7Jh"
      },
      "source": [
        "\r\n",
        "#### Cross Validation\r\n",
        "  - K-fold Cross Validation을 통해 성능 평가의 신뢰도를 높임\r\n",
        "  - 마찬가지로 Instance의 개수가 많지 않은 small dataset이기 때문에 **k=5**으로 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cda2I8hxxIQ6"
      },
      "source": [
        "# 추후 Model 성능 평가 시 활용하기 위한 cross_val_score Import\r\n",
        "\r\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyzkh6iSxwB7"
      },
      "source": [
        "#### Normalization & Standardization\r\n",
        "  - Model의 성능 개선을 위해 Normalization과 Standardization을 각각 적용\r\n",
        "  - Normalization: **Min-Max Normalization** 활용\r\n",
        "  - Standardization: **StandardScaler** 활용\r\n",
        "  - 모든 구현은 Pipeline을 통해 실험"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdnb1UB1tvy"
      },
      "source": [
        "# 추후 Model 성능 평가 시 전처리를 위한 Min-Max Scaler, Standard Scaler Import\r\n",
        "\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmGjtBA72IER"
      },
      "source": [
        "##6. Experiment\r\n",
        "*Multi-class Classification Experiment*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVIpYKnGisch"
      },
      "source": [
        "### ZeroR\r\n",
        "- 기준 Quality Value: **6**\r\n",
        "- 최종 Model Score: **0.4368** __(Baseline)__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoZlFsLji76Y",
        "outputId": "ac3089a3-b861-4e7d-9777-7ae59c450347"
      },
      "source": [
        "# quality feature 확인\r\n",
        "\r\n",
        "cleaned_df['quality']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       6\n",
              "1       6\n",
              "2       6\n",
              "3       6\n",
              "4       6\n",
              "       ..\n",
              "6491    6\n",
              "6492    5\n",
              "6494    6\n",
              "6495    5\n",
              "6496    6\n",
              "Name: quality, Length: 6394, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plaEX_7KjHuM",
        "outputId": "00df8d6b-7714-4b43-8691-552aa3f18b64"
      },
      "source": [
        "# quality feature의 각 category별 갯수 확인\r\n",
        "\r\n",
        "cleaned_df['quality'].value_counts(sort=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    2793\n",
              "5    2106\n",
              "7    1066\n",
              "4     212\n",
              "8     187\n",
              "3      25\n",
              "9       5\n",
              "Name: quality, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_9PRBDcjVGS",
        "outputId": "dd37a412-bf6a-4dd8-9fbe-908d3b093956"
      },
      "source": [
        "# 전체 Model들의 Score를 담을 Model_Score_Dict Dictionary 정의\r\n",
        "# ZeroR Score 계산\r\n",
        "\r\n",
        "Model_Score_Dict = {}\r\n",
        "Model_Score_Dict['ZeroR'] = 2793 / (2793 + 2106 + 1066 + 212 + 187 + 25 + 5)\r\n",
        "print(Model_Score_Dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ZeroR': 0.43681576477948075}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El220vxnkgJ5"
      },
      "source": [
        "### Experiment Design - Supervised Learning Pipeline\r\n",
        "  - 여러가지 Model들을 Pipeline으로 구성\r\n",
        "  - *__Scaler_dict__*: Normalization과 Standardization을 저장하는 Dictionary\r\n",
        "  - *__model_dict__*: Supervised Learning Algorithm들을 저장하는 Dictionary\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xS429GTD2n5"
      },
      "source": [
        "# Import Models\r\n",
        "\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.linear_model import Perceptron\r\n",
        "from sklearn import tree\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZTpt0ATFZl6"
      },
      "source": [
        "### Experiment 1 - Default Models (Without Hyperparameter Tuning)\r\n",
        "  - Cross Validation을 활용해 hyperparameter를 조정하지 않은 기본 Model들로 성능 평가\r\n",
        "  - 일정한 결과를 위해 *random_state* 값을 42로 설정 후 평가 진행\r\n",
        "  - Default model들에서는 여러 Warning들이 발생하는 것을 확인 가능\r\n",
        "    1. Logistic Regression에서 Max_iter가 너무 작아 Fail to converge에 대한 Warning\r\n",
        "    2. MLP에서 Max_iter = 200이 너무 작아 Optimization이 제대로 진행되지 않았음을 나타내는 Warning\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zKukYAgKyeN"
      },
      "source": [
        "# Dictionary 정의\r\n",
        "\r\n",
        "scaler_dict = {}\r\n",
        "scaler_dict['std_scaler'] = StandardScaler()\r\n",
        "scaler_dict['minmax_scaler'] = MinMaxScaler()\r\n",
        "\r\n",
        "model_dict = {}\r\n",
        "model_dict['gaussian_nb'] = GaussianNB()\r\n",
        "model_dict['logistic_regression_ovr'] = LogisticRegression(multi_class='ovr', random_state=42)\r\n",
        "model_dict['logistic_regression_multinomial'] = LogisticRegression(multi_class='multinomial', random_state=42)\r\n",
        "model_dict['perceptron'] = Perceptron(random_state=42)\r\n",
        "model_dict['decision_tree'] = tree.DecisionTreeClassifier(random_state=42)\r\n",
        "model_dict['knn'] = KNeighborsClassifier()\r\n",
        "model_dict['random_forest'] = RandomForestClassifier(random_state=42)\r\n",
        "model_dict['mlp'] = MLPClassifier(random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl-fr3XMEgIb",
        "outputId": "6053a436-9c09-41f7-cfb4-4a05ce1ebf87"
      },
      "source": [
        "# Default Model Experiment\r\n",
        "\r\n",
        "import pprint\r\n",
        "\r\n",
        "score_dict = {}\r\n",
        "\r\n",
        "for scaler in scaler_dict.keys():\r\n",
        "  for model in model_dict.keys():\r\n",
        "    pipe = Pipeline([('scaler', scaler_dict[scaler]), ('model', model_dict[model])])\r\n",
        "\r\n",
        "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\r\n",
        "    score_dict[f'{scaler}_{model}'] = scores.mean()\r\n",
        "\r\n",
        "print(\"\\n\")\r\n",
        "pp = pprint.PrettyPrinter(width=20, indent=4)\r\n",
        "pp.pprint(score_dict)\r\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "{   'minmax_scaler_decision_tree': 0.5826001955034213,\n",
            "    'minmax_scaler_gaussian_nb': 0.44007820136852394,\n",
            "    'minmax_scaler_knn': 0.5362658846529814,\n",
            "    'minmax_scaler_logistic_regression_multinomial': 0.5454545454545454,\n",
            "    'minmax_scaler_logistic_regression_ovr': 0.5390029325513196,\n",
            "    'minmax_scaler_mlp': 0.563049853372434,\n",
            "    'minmax_scaler_perceptron': 0.4328445747800586,\n",
            "    'minmax_scaler_random_forest': 0.6639296187683283,\n",
            "    'std_scaler_decision_tree': 0.5835777126099707,\n",
            "    'std_scaler_gaussian_nb': 0.44007820136852394,\n",
            "    'std_scaler_knn': 0.5481915933528836,\n",
            "    'std_scaler_logistic_regression_multinomial': 0.5458455522971651,\n",
            "    'std_scaler_logistic_regression_ovr': 0.5419354838709677,\n",
            "    'std_scaler_mlp': 0.561681329423265,\n",
            "    'std_scaler_perceptron': 0.4130987292277615,\n",
            "    'std_scaler_random_forest': 0.6649071358748777}\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ew8o2_bKTDA"
      },
      "source": [
        "#### 결과 해석\r\n",
        "- **Perceptron, Gaussian_nb**: 두 Scaler 모두 Baseline인 ZeroR의 **43.8%**보다 저조하거나 이와 비슷한 성능을 보였으므로 추후 실험에서 제외\r\n",
        "- **Random Forest**: Random Forest에서 두 Scaler가 유사한 **66%**대의 최고 성능을 보임\r\n",
        "- **그 외 Model**: 약 55%대의 성능들을 보이고 있으나, Convergence Warning을 다루기 위해 LR과 MLP의 *max_iter* 값을 조정 후 재평가 필요\r\n",
        "\r\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0bczBYTaT1i"
      },
      "source": [
        "#### Problem Statement\r\n",
        "1. ~feature들의 분포는 어떠한가? - *univariate analysis*~\r\n",
        "1. ~어떤 feature가 Class인 *quality*와 가장 상관성이 높은가? - *correlation analysis*~\r\n",
        "2. ~어떤 Model이 주어진 feature들을 통한 quality classification을 가장 잘 설명할 수 있는가? - *model selection problem*~\r\n",
        "3. 다양한 hyperparameter들을 조정하여 얻을 수 있는 best performance는 얼마인가? - *hyperparameter tuning*\r\n",
        "4. best performance를 얻은 model에서, 가장 중요한 3개의 feature는 무엇인가? - *feature selection problem*\r\n",
        "5. feature selection을 적용한 data에 대해 다시 model을 적용하였을 때 성능 차이는 어떠한가? - *feature selection problem*\r\n",
        "6. Clustering을 적용하였을 때에도 Classification Model과 유사한 결과를 얻을 수 있는가? - *unsupervised learning*\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BROhzFIMStfY"
      },
      "source": [
        "### Experiment 2 - Tuning ' *max_iter* '\r\n",
        "- 앞서 결과 해석에서 제시한 것처럼, 저조한 성능을 보인 Perceptron과 Gaussian_nb 삭제\r\n",
        "- Logistic Regression과 MLP의 Convergence Warning을 제거하기 위해, 'max_iter' parameter를 각각 2000, 5000의 값을 주고 재실험"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1W4eLu8SHIM"
      },
      "source": [
        "# Removing Perceptron and Gaussian NB\r\n",
        "\r\n",
        "del model_dict['perceptron']\r\n",
        "del model_dict['gaussian_nb']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmC3OKR8RtLB"
      },
      "source": [
        "# Tuning Hyperparameter\r\n",
        "\r\n",
        "model_dict['logistic_regression_ovr'] = LogisticRegression(multi_class='ovr', random_state=42, max_iter=2000)\r\n",
        "model_dict['logistic_regression_multinomial'] = LogisticRegression(multi_class='multinomial', random_state=42, max_iter=2000)\r\n",
        "model_dict['mlp'] = MLPClassifier(random_state=42, max_iter=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "394x8kf2SB26",
        "outputId": "f498ad92-e298-4930-ec56-24235d412453"
      },
      "source": [
        "# Default Model Experiment\r\n",
        "\r\n",
        "score_dict = {}\r\n",
        "\r\n",
        "for scaler in scaler_dict.keys():\r\n",
        "  for model in model_dict.keys():\r\n",
        "    pipe = Pipeline([('scaler', scaler_dict[scaler]), ('model', model_dict[model])])\r\n",
        "\r\n",
        "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\r\n",
        "    score_dict[f'{scaler}_{model}'] = scores.mean()\r\n",
        "\r\n",
        "print(\"\\n\")\r\n",
        "pp.pprint(score_dict)\r\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "{   'minmax_scaler_decision_tree': 0.5826001955034213,\n",
            "    'minmax_scaler_knn': 0.5362658846529814,\n",
            "    'minmax_scaler_logistic_regression_multinomial': 0.5454545454545454,\n",
            "    'minmax_scaler_logistic_regression_ovr': 0.5390029325513196,\n",
            "    'minmax_scaler_mlp': 0.5644183773216032,\n",
            "    'minmax_scaler_random_forest': 0.6639296187683283,\n",
            "    'std_scaler_decision_tree': 0.5835777126099707,\n",
            "    'std_scaler_knn': 0.5481915933528836,\n",
            "    'std_scaler_logistic_regression_multinomial': 0.5454545454545454,\n",
            "    'std_scaler_logistic_regression_ovr': 0.5419354838709677,\n",
            "    'std_scaler_mlp': 0.565982404692082,\n",
            "    'std_scaler_random_forest': 0.6649071358748777}\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th5aC_shULej"
      },
      "source": [
        "#### 결과 해석\r\n",
        "- 2,000과 5,000의 max_iter를 적용한 결과 Convergence Warning은 발생하지 않음\r\n",
        "- 하지만, LR과 MLP 모두 *0.3%*정도의 거의 없는 수준의 성능 개선이 이뤄짐: max_iter 외의 다른 hyperparameter의 조정이 필요\r\n",
        "- MinMaxScaler와 StandardScaler가 유사한 성능을 보이므로, Standard Scaler에 대해서만 실험 진행\r\n",
        "- 가장 좋은 성능을 보인 3개의 Model에 대해서만 추가 실험 진행\r\n",
        "  1. Random Forest\r\n",
        "  2. MLP\r\n",
        "  3. Decision Tree\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7cif1gDay5P"
      },
      "source": [
        "### Experiment 3 - Tuning Hyperparameters\r\n",
        "- MinMaxScaler 제거 및 상위 3개의 Model만 실험 (이외의 Model들은 제외)\r\n",
        "- Decision Tree의 경우 *max_leaf_nodes* parameter를 활용해 **Pruning** 진행\r\n",
        "- MLP의 경우 Regularization에 관여하는 alpha 값과, learning_rate를 조절\r\n",
        "- Random Forest의 경우 Decision Tree의 개수인 n_estimators를 조절\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N_Z0cK9kh0U"
      },
      "source": [
        "#### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKEr5BFDbOnX"
      },
      "source": [
        "# Removing MinMax Scaler and Bad Performance Models\r\n",
        "\r\n",
        "del scaler_dict['minmax_scaler']\r\n",
        "\r\n",
        "del model_dict['knn']\r\n",
        "del model_dict['logistic_regression_multinomial']\r\n",
        "del model_dict['logistic_regression_ovr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHQR5Qorc6HO",
        "outputId": "606eeeb2-de7a-4798-969c-84a8c8e94422"
      },
      "source": [
        "# Tuning Hyperparameter - Decision Tree Pruning\r\n",
        "\r\n",
        "max_leaf_list = [10, 50, 100, 200, 500, 1000, 1500, 2000]\r\n",
        "tree_score_list = []\r\n",
        "\r\n",
        "for max_leaf in max_leaf_list:\r\n",
        "  dt = tree.DecisionTreeClassifier(random_state=42, max_leaf_nodes= max_leaf)\r\n",
        "  scores = cross_val_score(dt, X_train, y_train, cv=5)\r\n",
        "  tree_score_list.append(scores.mean())\r\n",
        "\r\n",
        "print(\"\\n\")\r\n",
        "pp.pprint(tree_score_list)\r\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[   0.5274682306940371,\n",
            "    0.5532746823069403,\n",
            "    0.5542521994134897,\n",
            "    0.5595307917888562,\n",
            "    0.5652003910068426,\n",
            "    0.5835777126099707,\n",
            "    0.5837732160312805,\n",
            "    0.5837732160312805]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MObVan5ckE0N"
      },
      "source": [
        "##### Decision Tree 결과 해석\r\n",
        "- Decision Tree의 경우 max_leaf_list가 커질수록 전체적으로 성능이 개선됨\r\n",
        "- 이는 하부 Tree를 제거하여, 일반화 성능을 높이고 **Overfitting의 위험을 줄여주기 때문**으로 생각됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPAK_vAUknNq"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InqYEhP4f81N",
        "outputId": "8e8baeb4-b40d-478f-992e-c85e833c51f2"
      },
      "source": [
        "# Tuning Hyperparameter - MLP\r\n",
        "\r\n",
        "alpha_list = [0.01, 0.001, 0.0005]\r\n",
        "learning_rate_init_list = [0.01, 0.05, 0.001, 0.0005]\r\n",
        "mlp_score_list = []\r\n",
        "\r\n",
        "for alpha in alpha_list:\r\n",
        "  for learning_rate in learning_rate_init_list:\r\n",
        "    mlp = MLPClassifier(random_state=42, alpha= alpha, learning_rate_init= learning_rate, max_iter=2000)\r\n",
        "    scores = cross_val_score(mlp, X_train, y_train, cv=5)\r\n",
        "    mlp_score_list.append(scores.mean())\r\n",
        "\r\n",
        "print(\"\\n\")\r\n",
        "pp.pprint(mlp_score_list)\r\n",
        "print(\"\\n\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[   0.5206256109481916,\n",
            "    0.5204301075268817,\n",
            "    0.5300097751710655,\n",
            "    0.5264907135874878,\n",
            "    0.5071358748778103,\n",
            "    0.5043988269794721,\n",
            "    0.5270772238514174,\n",
            "    0.52297165200391,\n",
            "    0.5257086999022482,\n",
            "    0.52297165200391,\n",
            "    0.5219941348973607,\n",
            "    0.5290322580645161]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bGX5BTJk3OV"
      },
      "source": [
        "##### MLP 결과 해석\r\n",
        "- 다양한 alpha값과 learning_rate_init 값을 적용해보았으나, 유의미한 성능개선이 이뤄지지 않음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPXnK1NplMit"
      },
      "source": [
        "#### Random Forest\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5db4g-2jlgXI",
        "outputId": "a4604634-1079-451f-d589-ca0f3bb0411e"
      },
      "source": [
        "# Tuning Hyperparameter - Random Forest\r\n",
        "\r\n",
        "n_estimators_list = [100, 300, 500, 700]\r\n",
        "rf_score_list = []\r\n",
        "\r\n",
        "for estimators in n_estimators_list:\r\n",
        "  rf = RandomForestClassifier(random_state=42, n_estimators= estimators)\r\n",
        "  scores = cross_val_score(rf, X_train, y_train, cv=5)\r\n",
        "  rf_score_list.append(scores.mean())\r\n",
        "\r\n",
        "print(\"\\n\")\r\n",
        "pp.pprint(rf_score_list)\r\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[   0.6635386119257086,\n",
            "    0.6656891495601173,\n",
            "    0.6682306940371456,\n",
            "    0.6680351906158357]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de0x2C2slN-7"
      },
      "source": [
        "##### Random Forest 결과 해석\r\n",
        "- n_estimators= 500인 경우에 최고 성능 66.8%를 보임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYDGxOGEnqHk"
      },
      "source": [
        "#### 최종 결과\r\n",
        "- Random Forest에서 최고의 성능을 보임 (**66.8%**)\r\n",
        "- Random Forest의 hyperparameter인 n_estimators가 증가할수록 CV Score가 높아지는 경향을 보임 <br>(다양한 Decision Tree들을 활용해 Overfitting의 위험을 줄이기 때문으로 생각됨)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGMBupmEbCPD"
      },
      "source": [
        "#### Problem Statement\r\n",
        "1. ~feature들의 분포는 어떠한가? - *univariate analysis*~\r\n",
        "1. ~어떤 feature가 Class인 *quality*와 가장 상관성이 높은가? - *correlation analysis*~\r\n",
        "2. ~어떤 Model이 주어진 feature들을 통한 quality classification을 가장 잘 설명할 수 있는가? - *model selection problem*~\r\n",
        "3. ~다양한 hyperparameter들을 조정하여 얻을 수 있는 best performance는 얼마인가? - *hyperparameter tuning*~\r\n",
        "4. best performance를 얻은 model에서, 가장 중요한 3개의 feature는 무엇인가? - *feature selection problem*\r\n",
        "5. feature selection을 적용한 data에 대해 다시 model을 적용하였을 때 성능 차이는 어떠한가? - *feature selection problem*\r\n",
        "6. Clustering을 적용하였을 때에도 Classification Model과 유사한 결과를 얻을 수 있는가? - *unsupervised learning*\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDLdjhI8a34K"
      },
      "source": [
        "### Experiment 4 - Feature Selection\r\n",
        "- Random Forest의 Feature Importance를 바탕으로 가장 중요한 3개의 Feature 확인\r\n",
        "- Feature Selection Algorithm을 통해 Feature Select, 성능 평가\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcMjvz1muZ31"
      },
      "source": [
        "#### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "QGkwcjw8p3AP",
        "outputId": "c916ed7d-1535-4042-a579-4c26527fd816"
      },
      "source": [
        "# Printing and Visualizing Feature Ranking\r\n",
        "\r\n",
        "rf = RandomForestClassifier(random_state=42, n_estimators=500)\r\n",
        "rf.fit(X_train, y_train)\r\n",
        "\r\n",
        "importances = rf.feature_importances_\r\n",
        "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\r\n",
        "indices = np.argsort(importances)[::-1]\r\n",
        "\r\n",
        "print(\"Feature ranking:\")\r\n",
        "\r\n",
        "for f in range(X_train.shape[1]):\r\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "plt.title(\"Feature importances\")\r\n",
        "plt.bar(range(X_train.shape[1]), importances[indices],\r\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\r\n",
        "plt.xticks(range(X_train.shape[1]), indices)\r\n",
        "plt.xlim([-1, X_train.shape[1]])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "1. feature 10 (0.123571)\n",
            "2. feature 7 (0.103144)\n",
            "3. feature 1 (0.100009)\n",
            "4. feature 6 (0.092309)\n",
            "5. feature 4 (0.086986)\n",
            "6. feature 9 (0.086535)\n",
            "7. feature 5 (0.086372)\n",
            "8. feature 3 (0.084867)\n",
            "9. feature 8 (0.082173)\n",
            "10. feature 2 (0.079918)\n",
            "11. feature 0 (0.074115)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnOTAVJKsJA3",
        "outputId": "688f494e-cb2a-45b2-86c8-e37537d25d72"
      },
      "source": [
        "# What is feature 10, 7, 1?\r\n",
        "\r\n",
        "print(numeric_data.columns[10])\r\n",
        "print(numeric_data.columns[7])\r\n",
        "print(numeric_data.columns[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alcohol\n",
            "density\n",
            "volatile acidity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n7GEM63udM_"
      },
      "source": [
        "#### Selecting K-best features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23eu2mhTt35I",
        "outputId": "c637e143-1a2b-4dc2-8453-357d572d6f8c"
      },
      "source": [
        "# Select K-best Features\r\n",
        "\r\n",
        "from sklearn.feature_selection import SelectKBest, chi2\r\n",
        "\r\n",
        "k_list = [3, 5, 7, 9]\r\n",
        "k_score_list = []\r\n",
        "\r\n",
        "for val in k_list:\r\n",
        "  X_new = SelectKBest(chi2, k=val).fit_transform(X_train, y_train)\r\n",
        "  score = cross_val_score(rf, X_new, y_train, cv=5)\r\n",
        "  k_score_list.append(score.mean())\r\n",
        "\r\n",
        "print(k_score_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5562072336265884, 0.6531769305962853, 0.6600195503421309, 0.6694037145650048]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuIn-no7xXdc"
      },
      "source": [
        "#### 결과 해석\r\n",
        "- 일반적으로는 Feature를 추출해 Dataset을 재구성할 경우 일반화 성능이 올라감\r\n",
        "- 하지만 본 Data의 경우 **feature가 적은 편이며, Instance 개수 또한 적은 small-dataset**에 속해 k를 3 정도로 줄 경우 오히려 성능이 대폭 감소\r\n",
        "- Data들이 고르게 분포 되어 있지 않은 것 또한 성능 감소에 영향을 미쳤으리라 생각됨\r\n",
        "- 거의 대부분의 feature인 9개를 선택할 때, hyperparameter를 tuning해 얻은 성능(66.8%)에 준하는 성능이 나옴을 알 수 있음\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7noM00M30uj-"
      },
      "source": [
        "#### Problem Statement\r\n",
        "1. ~feature들의 분포는 어떠한가? - *univariate analysis*~\r\n",
        "1. ~어떤 feature가 Class인 *quality*와 가장 상관성이 높은가? - *correlation analysis*~\r\n",
        "2. ~어떤 Model이 주어진 feature들을 통한 quality classification을 가장 잘 설명할 수 있는가? - *model selection problem*~\r\n",
        "3. ~다양한 hyperparameter들을 조정하여 얻을 수 있는 best performance는 얼마인가? - *hyperparameter tuning*~\r\n",
        "4. ~best performance를 얻은 model에서, 가장 중요한 3개의 feature는 무엇인가? - *feature selection problem*~\r\n",
        "5. ~feature selection을 적용한 data에 대해 다시 model을 적용하였을 때 성능 차이는 어떠한가? - *feature selection problem*~\r\n",
        "6. Clustering을 적용하였을 때에도 Classification Model과 유사한 결과를 얻을 수 있는가? - *unsupervised learning*\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psJ4iI9kyfWA"
      },
      "source": [
        "### Experiment 5 - Test Accuracy\r\n",
        "- 앞서 hyperparameter들을 tuning한 Decision Tree, MLP, Random Forest Model에 대해 Test Accuracy 평가\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jaud-ydzJVO",
        "outputId": "35dd914a-4f89-4d7a-c691-0558770403cf"
      },
      "source": [
        "# Print Test Accuracy of 3 models\r\n",
        "\r\n",
        "dt.fit(X_train, y_train)\r\n",
        "mlp.fit(X_train, y_train)\r\n",
        "rf.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(dt.score(X_test, y_test))\r\n",
        "print(mlp.score(X_test, y_test))\r\n",
        "print(rf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6184519155590305\n",
            "0.5347928068803753\n",
            "0.6982017200938233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCRQPBCIzsbW"
      },
      "source": [
        "#### 결과 해석\r\n",
        "- 모두 Training Phase보다 1~2% 정도 좋은 성능을 보임\r\n",
        "- Decision Tree의 Pruning, Random Forest의 n_estimators와 Cross Validation을 활용해 **Overfitting의 위험성을 줄였기 때문**으로 생각됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEz3IU3GYdd"
      },
      "source": [
        "### Experiment 6 - Unsupervised Learning(Clustering)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7n5toJbHaQ3"
      },
      "source": [
        "- K-means Algorithm을 활용해 Unsupervised Learning 진행\r\n",
        "- Cluster의 개수는 Label이 갖는 value들의 개수인 7로 설정 (3 ~ 9)\r\n",
        "- 일정한 출력값을 위해 random_state = 42로 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa9l4WBFHLHq",
        "outputId": "20e84a5b-deea-4d26-ae93-413d3fdc85dd"
      },
      "source": [
        "# K-means clustering with 7 clusters\r\n",
        "\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "\r\n",
        "kmeans = KMeans(n_clusters=7, random_state=42)\r\n",
        "kmeans.fit(numeric_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=42, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBsBMR0xH1Jj",
        "outputId": "e4b3507d-e974-4eaf-d3dc-595dab526d55"
      },
      "source": [
        "# Print New labels made by kmeans cluster\r\n",
        "\r\n",
        "import collections\r\n",
        "\r\n",
        "new_labels = kmeans.predict(numeric_data)\r\n",
        "collections.Counter(new_labels) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 905, 1: 1112, 2: 876, 3: 697, 4: 361, 5: 1356, 6: 1087})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmn_tyAkJOSw",
        "outputId": "d6a86c35-f6e1-4e64-cee2-487ec1bcfbec"
      },
      "source": [
        "# Original values of 'quality' labels\r\n",
        "\r\n",
        "cleaned_df['quality'].value_counts(sort=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    2793\n",
              "5    2106\n",
              "7    1066\n",
              "4     212\n",
              "8     187\n",
              "3      25\n",
              "9       5\n",
              "Name: quality, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2na3RESrKGJW"
      },
      "source": [
        "# Re-labeling by value frequencies\r\n",
        "\r\n",
        "new_labels_cor = np.empty(label.shape)\r\n",
        "\r\n",
        "for i in range(len(new_labels)):\r\n",
        "  if new_labels[i] == 5:\r\n",
        "    new_labels_cor[i] = 6\r\n",
        "  if new_labels[i] == 1:\r\n",
        "    new_labels_cor[i] = 5\r\n",
        "  if new_labels[i] == 6:\r\n",
        "    new_labels_cor[i] = 7\r\n",
        "  if new_labels[i] == 0:\r\n",
        "    new_labels_cor[i] = 4\r\n",
        "  if new_labels[i] == 2:\r\n",
        "    new_labels_cor[i] = 8\r\n",
        "  if new_labels[i] == 3:\r\n",
        "    new_labels_cor[i] = 3\r\n",
        "  if new_labels[i] == 4:\r\n",
        "    new_labels_cor[i] = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cprFmtQmLo8G",
        "outputId": "8fabebbd-c322-44de-bac8-838ad7508ea1"
      },
      "source": [
        "# Cross Tabulation\r\n",
        "\r\n",
        "crosstab_df = pd.DataFrame({'labels': label, 'clustered_digits':new_labels_cor})\r\n",
        "ct = pd.crosstab(crosstab_df['labels'], crosstab_df['clustered_digits'])\r\n",
        "print(ct)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clustered_digits  3.0  4.0  5.0  6.0  7.0  8.0  9.0\n",
            "labels                                             \n",
            "3                   5    9    2    3    2    3    1\n",
            "4                  43   38   19   30   40   34    8\n",
            "5                 256  320  370  345  270  377  168\n",
            "6                 304  381  490  613  483  362  160\n",
            "7                  78  144  188  304  245   89   18\n",
            "8                  11   13   42   58   46   11    6\n",
            "9                   0    0    1    3    1    0    0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMNSWF0vNAqK"
      },
      "source": [
        "#### 결과 해석\r\n",
        "- 전체적으로, Clustering을 통해서는 정확한 예측이 어려움\r\n",
        "- label이 5, 6, 7인 경우만 어느 정도 근접한 예측이 가능하며, 그 이외에는 크게 의미가 없음\r\n",
        "- 이는 원래 Dataset의 **Class간 Imbalance가 크기 때문**으로 생각됨 (5, 6, 7의 quality가 가장 많고, 3, 4, 8, 9의 quality는 극소수)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57ZD-QuTRNZo"
      },
      "source": [
        "## 7. 결론\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QLdkKs0Yr7S"
      },
      "source": [
        "### Best Performance\r\n",
        "- 여러 전처리 과정과 Hyperparameter Tuning을 한 결과, **Random Forest**에서 **66.8%**의 최고 성능을 보임\r\n",
        "- 이는 좋은 성능이라고 보기엔 다소 낮은 감이 있으며, 그 원인은 다음과 같다고 생각됨\r\n",
        "  1. 약 6,500개의 **small-size dataset**\r\n",
        "  2. Wine Quality라는 label의 특성상, 5, 6, 7의 중간 점수대에 많이 분포하는 **Imbalanced Class**\r\n",
        "\r\n",
        "### Overfitting Problem\r\n",
        "- Overfitting을 방지하기 위한 여러 Model 및 처리를 했기 때문에, Overfitting 문제는 크게 발생하지 않음\r\n",
        "\r\n",
        "### Feature Importance & Selection\r\n",
        "- Random Forest에서 Feature Importance를 측정해 본 결과, Correlation Analysis에서 가장 높은 상관관계를 보였던 <br>'Alcohol' Feature와 'Density' Feature가 마찬가지로 높은 Importance를 보임\r\n",
        "- Feature Selection을 진행해 본 결과, small-size dataset이라는 한계 때문에 적은 Feature를 선택하면 오히려 성능이 떨어지는 경향을 보임\r\n",
        "\r\n",
        "### Clustering\r\n",
        "- 중간 정도의 quality인 5, 6, 7점의 경우만 어느 정도 일치하는 경향을 보이며, 그 외에는 완전히 상반된 결과가 나옴\r\n",
        "- 마찬가지로 Imbalanced Class와 Small-size dataset에서 기인한 것으로 생각됨"
      ]
    }
  ]
}
